# API Environment Variables
# Copy this file to .env and configure

# Application
APP_ENV=development
DEBUG=true
SECRET_KEY=your-secret-key-here-minimum-32-chars-long
PORT=8000

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
AI_MODEL=gpt-4o-mini

# Redis Configuration
# For local: redis://localhost:6379/0
# For production: Use your Redis cloud service URL
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# File Processing
FILE_MAX_MB=20
MAX_BATCH_SIZE=50
RESULTS_TTL_SECONDS=86400

# Rate Limiting
MAX_RPS=8

# NPS Calculation Configuration
# Methods: standard, absolute, weighted, shifted (default)
# shifted: Transforms NPS from [-100,100] to [0,100] scale (0=worst, 50=neutral, 100=best)
NPS_CALCULATION_METHOD=shifted
# NPS_PASSIVE_WEIGHT=0.5  # Only used with 'weighted' method

# Parallel Processing Configuration
OPENAI_CONCURRENT_WORKERS=4  # Number of parallel API calls (1-10)
BATCH_SIZE_OPTIMAL=120  # Optimal batch size for token limits (50-200)
ENABLE_PARALLEL_PROCESSING=true  # Enable async parallel processing
ENABLE_COMMENT_CACHE=true  # Cache analyzed comments to reduce API calls
CACHE_TTL_DAYS=7  # Cache retention in days (1-30)

# Performance Monitoring
LOG_PERFORMANCE_METRICS=true  # Log detailed performance metrics
ALERT_THRESHOLD_SECONDS=15  # Alert if processing exceeds this threshold

# Celery Worker Configuration
CELERY_WORKER_CONCURRENCY=4

# Optional
LOG_LEVEL=INFO
# SENTRY_DSN=your-sentry-dsn-here
# DATABASE_URL=postgresql://user:pass@localhost/db